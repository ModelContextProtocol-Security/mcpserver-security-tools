---
arxiv_id: "2512.14166"
title: "IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol"
authors: [Yunhao Yao, Zhiqiang Wang, Haoran Cheng, Yihang Cheng, Haohua Du, Xiang-Yang Li]
institutions: [University of Science and Technology of China, Beijing University of Aeronautics and Astronautics]
analyzed: 2026-02-04
---

## Paper Summary

This paper identifies a **novel privacy threat** called Intent Inversion, where semi-honest MCP servers can reconstruct user intent solely by analyzing legitimate tool calls. It proposes IntentMiner, a framework achieving 85%+ semantic alignment with original user queries.

**Core contribution:** First to formalize privacy risks from semi-honest third-party MCP servers observing tool interaction logs.

**Key finding:** Tool usage patterns contain rich semantic traces - even without seeing the original query, servers can infer sensitive user intents.

## Attack/Threat Coverage

### Novel Attack: Intent Inversion

**Definition:** A semi-honest MCP server attempts to reconstruct the user's private underlying intent solely by analyzing legitimate tool calls.

**Threat Model:**
- Attacker: Semi-honest MCP server
- Capability: Observes tool documentation, invocation data, execution results
- Goal: Reconstruct user's private query intent

**Example scenario:**
Tool call: `Heart_Healthy_Food_Recommender(user_health_condition={blood_pressure: High, cholesterol_level: Borderline High, blood_sugar_level: Prediabetes})`

Inferred intent: User has high blood pressure, borderline high cholesterol, prediabetes and is seeking dietary recommendations.

### Attack Formalization

Given:
- User query Q
- Agent A parses Q and retrieves n tools
- Tool sequence ⟨T₁(p₁), ..., Tₙ(pₙ)⟩ sent to MCP server M
- Results R₁, ..., Rₙ returned

Attacker M attempts to infer intent I:
```
F = arg min_F G(I, Q)
I = F({Doc(T₁),...,Doc(Tₙ)}, ⟨T₁(p₁),...,Tₙ(pₙ)⟩, {R₁,...,Rₙ})
```

Where F is intent inference model and G measures alignment.

### Attacker Capabilities (inherent to MCP workflow)

1. **Tool Documentation** - Registered tool descriptions and schemas
2. **Invocation Data** - Tool names and input parameters
3. **Execution Results** - Output generated by tools

**Key insight:** These data sources require no additional adversarial actions - they're inherent to legitimate MCP operation.

### Distinction from Prior Work

| Attack Type | Target | Attacker |
|-------------|--------|----------|
| Model Inversion | Training data from model outputs | Model API access |
| Membership Inference | Whether record was in training | Model outputs |
| Attribute Inference | Private user attributes | Text embeddings |
| **Intent Inversion (new)** | Dynamic user intent | Tool interaction logs |

## Defense/Mitigation Proposals

### Defensive Strategies Mentioned

The paper primarily demonstrates the attack; defensive strategies are mentioned briefly:
- Need for privacy-preserving tool invocation mechanisms
- Potential for differential privacy in tool parameters
- Limiting information in tool execution results

**Gap:** No concrete defense implementation provided.

## IntentMiner Framework

### Architecture

Three components:
1. **Hierarchical Information Isolation** - Segregates tool call data to prevent interference
2. **Three-Dimensional Semantic Analysis** - Synthesizes insights from multiple perspectives
3. **Step-Level Intent Parse** - Analyzes intent at each tool call level

### Three-Dimensional Semantic Analysis

#### 1. Tool Purpose Analysis
- Extract purposes from tool name
- Identify intended use cases from description
- Determine problem domain

#### 2. Call Statement Analysis
- Extract parameters from tool call
- Align with Required Field in schema
- Refine inferred intent with entity information

#### 3. Returned Result Analysis
- Align results with parameters
- Validate intent from Call Statement Analysis
- Revise intent using detailed output information

### Algorithm

For each tool call i:
1. I_tmp ← F(T_i, Doc(T_i).desc) [Tool Purpose]
2. I_ref ← F(I_tmp, Doc(T_i).reqd, p_i) [Call Statement]
3. I_i ← F(I_ref, Doc(T_i).prop, R_i) [Returned Result]

Final: I = F_agg(I_1, ..., I_n)

## Experimental Results

### Dataset
**ToolACE:** 26,507 distinct tools, 11,300 multi-turn dialogues, 1,043 with tool invocations

### Evaluation Metrics

1. **Intent Alignment (A_intent):** LLM evaluators judge if inferred intent aligns with original query
2. **Text Embedding Similarity (S_text):** Cosine similarity using MPNet-Base
3. **Entity Match Ratio (M_entity):** Named entity overlap using BERT-Large NER

### Results

| Reasoner LLM | A_intent | S_text | M_entity |
|--------------|----------|--------|----------|
| GPT-4.1 | 83.13% | 81.39% | 84.41% |
| Claude-3.5 | 76.22% | 74.82% | 78.05% |
| Gemini-2.5 | 85.71% | 80.12% | 78.67% |
| Llama-3.1 | 83.99% | 77.54% | 75.38% |
| DeepSeek-V3 | 82.55% | 80.63% | 81.01% |
| Qwen3 | 74.78% | 76.29% | 81.28% |

**Key finding:** >83% intent alignment in most cases, demonstrating significant privacy risk.

### Evaluator Consistency

Using GPT-5.0, Claude-4.0, DeepSeek-R1 as evaluators:
- Results varied by no more than 3.83% across evaluators
- Demonstrates stable, non-outlier-dependent performance

## Discoveries (for inventory)

### Dataset
- **ToolACE** - Large-scale dataset for tool retrieval research

### Key Insight for Taxonomy
- **Semi-honest MCP servers** - New adversary class distinct from malicious servers
- **Intent Inversion** - New attack category for MCP threat models

## Extractable Assets

### Threat Model Components

| Component | Trust Level | Justification |
|-----------|-------------|---------------|
| User | Trusted | Authority over server selection and requests |
| LLM Agent | Trusted | Secured local/verified cloud environment |
| MCP Server | Semi-honest | Third-party, outside user control |

### Evaluation Prompts

The paper includes detailed prompts for:
- IntentMiner's three-dimensional analysis
- LLM evaluator alignment assessment

### Intent Alignment Formula

```
A_intent(I, Q) = (1/k) Σ G_i(I, Q)
```

Where G_i returns 1 if evaluator i determines I aligns with Q.

## Limitations & Gaps

**Acknowledged:**
- Evaluated on ToolACE dataset (synthetic)
- Focuses on SSE transport mechanism
- Defense strategies not fully developed

**Not addressed:**
- Real-world deployment validation
- Countermeasures implementation
- Multi-hop inference across multiple servers

## Notable Observations

1. **Privacy vs. functionality trade-off** - Rich tool call information enables both capability and privacy leakage
2. **Semi-honest is realistic** - Servers may be "curious but correct" - following protocol while inferring
3. **85%+ accuracy is alarming** - High success rate with only legitimate observations
4. **No additional attack needed** - Inference possible from normal operation
5. **Health example is visceral** - Medical conditions inferred from food recommendation tool
6. **New attack surface** - Distinct from prompt injection, tool poisoning - focuses on inference
7. **LLM-as-attacker** - Uses LLM reasoning for intent reconstruction
8. **Step-level granularity** - Analyzing individual tool calls improves accuracy
