---
arxiv_id: "2601.07395"
title: "MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP"
authors: [Ruiqi Li, Zhiqiang Wang, Yunhao Yao, Xiang-Yang Li]
institution: University of Science and Technology of China
analyzed: 2026-02-04
---

## Paper Summary

This paper proposes **MCP-ITP**, the first automated framework for **implicit tool poisoning** in MCP. Unlike explicit tool poisoning where the malicious tool is invoked, implicit poisoning keeps the poisoned tool dormant while manipulating the agent to invoke a legitimate high-privilege tool for malicious operations.

**Core contribution:** Automated generation of stealthy poisoned tools achieving 84.2% ASR while suppressing detection to 0.3%.

**Key finding:** Current defenses are insufficient - implicit poisoning is highly effective and nearly undetectable.

## Attack/Threat Coverage

### Implicit vs. Explicit Tool Poisoning

| Type | Poisoned Tool Behavior | Detection Risk |
|------|----------------------|----------------|
| Explicit | Directly invoked to execute malicious logic | High - monitored |
| **Implicit** | Never invoked; manipulates context to redirect to legitimate tool | Low - no suspicious execution |

### Attack Mechanism

1. Malicious MCP server B exposes poisoned tool T_K
2. T_K's description contains crafted instructions
3. Agent connects to benign server A (tools T_A) and malicious server B
4. Poisoned metadata injected into agent's context
5. User query intended for tool T_A gets hijacked
6. Agent invokes legitimate high-privilege tool T_G instead
7. T_K is never executed - attack remains stealthy

### Example Attack

**Poisoned tool "qubit"** (never invoked):
- Description contains hidden instructions
- User asks to read a file
- Agent redirected to call `write_file` modifying SSH private key

### Threat Model

**Trusted:**
- Users (honest, non-colluding)
- MCP Host (contains LLM agent, manages communication)

**Untrusted:**
- MCP Servers (can expose poisoned tools)

**Attacker capabilities:**
- Black-box (no access to user queries or LLM parameters)
- Can inspect benign server's toolset
- Can craft and publish poisoned tools

### Attack Formalization

**Goal:** For any query Q that would invoke original tool T_A:
- Redirect to high-privilege tool T_G ∈ T_A, T_G ≠ T_A
- Ensure poisoned tool T_K remains dormant (never executed)
- Evade malicious tool detection mechanisms

## Defense/Mitigation Proposals

### MCP-ITP Framework (Attack Generation)

The paper proposes an attack framework, not defenses. Components:

#### 1. Attacker LLM (L_A)
- Iteratively optimizes poisoned tool descriptions
- Generates candidate poisoned tools
- Uses feedback from previous iterations

#### 2. Detector LLM (L_D)
- Simulates malicious tool detection
- Provides evasiveness feedback
- Binary label + rationale for each candidate

#### 3. Evaluator LLM (L_E)
- Tests attack effectiveness on shadow queries
- Measures if target tool T_G is invoked
- Provides effectiveness feedback

### Optimization Algorithm

```
desc(T_K) = R ⊕ S
```

Where:
- R: Camouflage description (semantic alignment with T_A)
- S: Implicit poisoning payload (iteratively optimized)

**Two strategies for R:**
1. **Copy-based:** R = desc(T_A) directly
2. **Paraphrase-based:** LLM rephrases desc(T_A)

**Optimization objective:**
```
max_S (1/m) Σ I(L_E(q_i, T_A ∪ {T_K(S)}) = n_g)
```

### Insights for Defense

Paper implies needed defenses:
- Detection of implicit manipulation patterns
- Context isolation between servers
- Semantic analysis of tool description intent vs. capability
- Monitoring for unexpected tool invocation patterns

## Experimental Results

### Dataset
**MCPTox:** 45 real-world MCP servers, 353 real tools, 1,497 malicious test cases (548 implicit poisoning)

### Models Tested
12 LLM agents including:
- GPT-3.5-turbo, o1-mini, GPT-4o-mini
- DeepSeek-R1, DeepSeek-V3
- Gemini-2.5-flash
- Qwen3-8b, Qwen3-32b, Qwen3-235b-a22b (with/without reasoning)

### Attack Success Rates (ASR)

| Model | MCP-ITP ASR | MCPTox Baseline ASR | Improvement |
|-------|-------------|---------------------|-------------|
| GPT-3.5-turbo | 84.2% | 48.2% | +36.0% |
| o1-mini | 82.9% | 59.5% | +23.4% |
| GPT-4o-mini | 72.5% | 54.0% | +18.5% |
| DeepSeek-R1 | 66.7% | 66.0% | +0.7% |
| DeepSeek-V3 | 78.4% | 44.8% | +33.6% |
| Qwen3-32b+ | 69.9% | 45.1% | +24.8% |
| Qwen3-32b | 28.8% | 9.5% | +19.3% |

### Malicious Tool Detection Rate (MDR)

| Setting | MDR |
|---------|-----|
| Minimum achieved | 0.3% |
| Typical | <5% |

**Key finding:** MCP-ITP dramatically reduces detection while increasing attack success.

### Reasoning Mode Impact

Models with reasoning enabled (Qwen3+) show higher ASR:
- Qwen3-8b: 7.4% → 40.5% (with reasoning)
- Qwen3-32b: 28.8% → 69.9% (with reasoning)

## Discoveries (for inventory)

### Dataset
- **MCPTox** - Benchmark dataset for MCP tool poisoning evaluation

### Tools/Projects Referenced
- AutoMalTool - Automated malicious MCP tool generation (explicit poisoning)

### Key Metrics

| Metric | Definition |
|--------|------------|
| ASR (Attack Success Rate) | N_sa / N_vr (successful attacks / valid responses) |
| MDR (Malicious Tool Detection Rate) | N_m / N_v (flagged malicious / valid outputs) |

## Extractable Assets

### Implicit Poisoning Taxonomy

| Attack Type | Poisoned Tool Invoked | Target |
|-------------|----------------------|--------|
| Explicit (prior work) | Yes | Poisoned tool itself |
| **Implicit (this paper)** | No | Legitimate high-privilege tool |

### Optimization Algorithm (Algorithm 1)

Key parameters:
- N: Number of candidates per iteration
- W: Tree width (retained candidates)
- T: Maximum iterations
- α: Acceptance threshold

### Evasiveness Strategy

When detector flags as malicious:
```
TotalS[S_i] = TotalS[S_i] - m/2
```

Penalizes detected candidates, guiding optimization toward evasiveness.

## Limitations & Gaps

**Acknowledged:**
- Single detector model (Qwen3-8b) - may not represent all defenses
- Black-box assumption - white-box attacks unexplored
- Dataset scope (MCPTox subset)

**Implications:**
- Current detection methods fundamentally insufficient
- Need for context-aware, behavioral detection
- Implicit attacks harder to address than explicit

## Notable Observations

1. **Implicit > Explicit** - Implicit poisoning is more dangerous because it's stealthier
2. **Reasoning increases vulnerability** - Models with reasoning enabled are MORE susceptible (69.9% vs 28.8%)
3. **Detection rate near zero** - 0.3% MDR means essentially undetectable
4. **84.2% ASR** - Very high attack success on GPT-3.5-turbo
5. **Automated optimization** - Black-box search effectively crafts evasive payloads
6. **Legitimate tools weaponized** - Attack uses victim's own trusted tools
7. **Decoupling of trigger and action** - Key insight for stealthiness
8. **Real MCP servers used** - 45 real-world servers validates practical threat
